# 08-31-2021 Text Normalization

---

#ðŸ“¥
Class: #NLP
Week: #week/week-2
Tags: 
Related:

---

Unix tool can be used to build quick word count stats for any corpus
Tokenization: parsing cprpuses for individual words
Word normalization: the task of putting words and tokens into a standard format, choosing a single normal form for words with multiple forms
Lemmatization: determining that two words have the same root despite surface differences 
Stemming: a more striaghtforward way to lower the number of tokens in a corpus where you turn parts of  word into other more simple fragments
**Ex: âœ**  sses -> ss (grasses -> grass)
Sentence segmentation: segmenting text into sentences 