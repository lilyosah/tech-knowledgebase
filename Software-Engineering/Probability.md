# Probability
#ðŸ“¥ 
%%
#topic
#concept
**Related:**
-  [[Algo MOC]]
-  [[NLP Table of Contents]]

%%

Conditional Probability
P(A|B) = P(A, B)/P(B)

Let C -> Aand x -> B

Bayes rule
$class(x) = arg max\dfrac{(P(ci, x))}{P(x))}$
$Ci \in C$

Computing $P(ci, x)$ is very hard, that's where Bayes theorem comes in

Which gets to 
P(C|x) = (P(x|C)P(C))/P(x)

If you know 
$P(c|x) = .6$  and $P(o|x) = .4$, you can do 

$1 = P(c|x) + P(o|x)$

Bayes Rule:
$$P(c|x) = \frac{P(x|c)(P(c))}{P(x)}$$
$$1 = P(x|c$$


Has something to do with probability distribution
Gaussian Normal:
- A function that plots some numbers?
- Parameters are normal  distribution and standard deviation?
Bernoulli: A discreet probability? $P(c)$ in this case?
- Deals with two classes of things

$L(\theta|X)$
$\theta$ is the graph thing he drew
$L(P|X)$
$\frac{dL}{dp}$
$dl = p(o)$

